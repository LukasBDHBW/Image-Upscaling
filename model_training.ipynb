{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8702,"status":"ok","timestamp":1687427997018,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"Evh_r8dmRavT"},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","import math\n","from torchvision.transforms import ColorJitter, Normalize\n","from torch.utils.data import ConcatDataset\n","from torch.utils.data import Subset\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VrjMPPdsa8zL"},"source":["### data loading (with augmentation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"elapsed":358973,"status":"error","timestamp":1687428359694,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"Hmwoaegma5-b","outputId":"64f003ce-dd79-461d-ce76-d96e392d1236"},"outputs":[],"source":["# low_res_folder = \"./drive/MyDrive/dog_low_res\"\n","# high_res_folder = \"./drive/MyDrive/dog\"\n","\n","\n","# # === creating dataset with all images ===\n","# class CustomDataset(Dataset):\n","#     def __init__(self, low_res_folder, high_res_folder, transform=None):\n","#         self.low_res_images = sorted(os.listdir(low_res_folder))\n","#         self.high_res_images = sorted(os.listdir(high_res_folder))\n","#         self.transform = transform\n","\n","#     def __len__(self):\n","#         return len(self.low_res_images)\n","\n","#     def __getitem__(self, index):\n","#         low_res_image = Image.open(os.path.join(low_res_folder, self.low_res_images[index]))\n","#         high_res_image = Image.open(os.path.join(high_res_folder, self.high_res_images[index]))\n","\n","#         if self.transform is not None:\n","#             low_res_image = self.transform(low_res_image)\n","#             high_res_image = self.transform(high_res_image)\n","\n","#         return low_res_image, high_res_image\n","\n","# # transform to tensor\n","# base_transform = transforms.Compose([\n","#     transforms.ToTensor()\n","# ])\n","\n","# # original dataset\n","# dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n","\n","\n","\n","# # === Splitting into train and val sets ===\n","\n","# train_size = 0.8  # Proportion of data to be used for training\n","# dataset_size = len(dataset)\n","# split = int(train_size * dataset_size)\n","# train_indices = list(range(split))\n","# val_indices = list(range(split, dataset_size))\n","\n","# # Create train dataset as a subset of the combined dataset\n","# train_dataset = Subset(dataset, train_indices)\n","\n","# # Create val dataset as a subset of the combined dataset\n","# val_dataset = Subset(dataset, val_indices)\n","\n","\n","\n","# # === Normalization ===\n","# normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","\n","# train_dataset = [(normalize(image), normalize(target)) for image, target in train_dataset]\n","\n","# val_dataset = [(normalize(image), normalize(target)) for image, target in val_dataset]\n","\n","\n","\n","# # === train_data augmentation ===\n","\n","# # color jitter augmentation for training\n","# train_color_jitter = ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n","\n","# # augmentation factor\n","# augmentation_factor = 2\n","\n","# # augmented datasets with random color jitter\n","# augmented_datasets = []\n","# for _ in range(augmentation_factor):\n","#     augmented_dataset = []\n","#     for image, target in train_dataset:\n","#         augmented_dataset.append((train_color_jitter(image), train_color_jitter(target)))\n","#     augmented_datasets.append(augmented_dataset)\n","\n","# # combine original and augmented datasets\n","# combined_datasets = [train_dataset] + augmented_datasets\n","# combined_dataset = ConcatDataset(combined_datasets)\n","\n","\n","\n","# # === final data loaders ===\n","\n","# # Data loaders for train and val sets\n","# batch_size = 32\n","# train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n","# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# # Number of samples in each set\n","# print(f\"Number of training samples originally: {len(train_dataset)}, now augmented to: {len(combined_dataset)}\")\n","# print(f\"Number of val samples: {len(val_dataset)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["low_res_folder = \"/kaggle/working/dog_low_res\"\n","high_res_folder = \"/kaggle/input/animal-faces/afhq/train/dog\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","# transform to tensor & normalize\n","normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","\n","base_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","# original dataset\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n","\n","\n","\n","# === Splitting into train and val sets ===\n","\n","train_size = 0.8  # Proportion of data to be used for training\n","dataset_size = len(dataset)\n","split = int(train_size * dataset_size)\n","train_indices = list(range(split))\n","val_indices = list(range(split, dataset_size))\n","\n","# Create train dataset as a subset of the combined dataset\n","train_dataset = Subset(dataset, train_indices)\n","\n","# Create val dataset as a subset of the combined dataset\n","val_dataset = Subset(dataset, val_indices)\n","\n","\n","\n","# === final data loaders ===\n","\n","# Data loaders for train and val sets\n","batch_size = 128\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# Number of samples in each set\n","print(f\"Number of training samples originally: {len(train_dataset)}\")\n","print(f\"Number of val samples: {len(val_dataset)}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eRnCPEdja_mT"},"source":["### SRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303652,"status":"ok","timestamp":1687426760337,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"0gzlOYjOZVy8","outputId":"985020d4-02da-4d2d-fa4e-06dbf6ef8801"},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = SRCNN().to(device)\n","\n","# hyperparameters\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training process\n","for epoch in range(num_epochs):\n","    for input_data, desired_data in train_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / loss.item())\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","    # Validating the model (on validation data)\n","    for input_data, desired_data in val_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / loss.item())\n","\n","    print(f\"Loss (validation): {loss.item():.4f}, PSNR (validation): {psnr}\")\n","\n","# saving the model\n","torch.save(model.state_dict(), \"SRCNN.pth\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIwglB9obBWf"},"source":["### FSRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241593,"status":"ok","timestamp":1687427178503,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"61XUL-tBbCVo","outputId":"9314a921-3999-427f-8208-8816e981bb22"},"outputs":[],"source":["class FSRCNN(nn.Module):\n","    def __init__(self, d=56, s=12, m=4):\n","        super(FSRCNN, self).__init__()\n","        # Feature Extraction\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","        # Shrinking\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","        # Non-linear Mapping\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","        # Expanding\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        # Deconvolution\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=5, padding=4, output_padding=4)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = FSRCNN().to(device)\n","\n","# hyperparameters\n","learning_rate = 0.001\n","num_epochs = 40\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training process\n","for epoch in range(num_epochs):\n","    for input_data, desired_data in train_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / loss.item())\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","    # Validating the model (on validation data)\n","    val_loss = 0\n","    number_batches = 0\n","    for input_data, desired_data in val_loader:\n","        number_batches += 1\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        val_loss += loss.item()\n","    \n","    val_loss_avg = val_loss / number_batches   \n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / val_loss_avg)\n","\n","    print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","\n","\n","# saving the model\n","torch.save(model.state_dict(), \"FSRCNN.pth\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yrLNqyDyJt2P"},"source":["### Bicubic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1074,"status":"ok","timestamp":1687427876086,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"An0Ri4gtJZbC","outputId":"b5d806d6-c5f7-4dbe-f07a-69012eb94eef"},"outputs":[],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = bicubic().to(device)\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","# Validating the model (on validation data)\n","for input_data, desired_data in val_loader:\n","    # Move input and desired images to device\n","    input_data = input_data.to(device)\n","    desired_data = desired_data.to(device)\n","\n","    # Forward pass\n","    output_images = model(input_data)\n","\n","    # Calculate loss\n","    loss = criterion(output_images, desired_data)\n","\n","# Print training loss per epoch\n","psnr = 10 * math.log10(1 / loss.item())\n","\n","print(f\"Loss (validation): {loss.item():.4f}, PSNR (validation): {psnr}\")\n","\n","\n","# saving the model\n","torch.save(model.state_dict(), \"bicubic.pth\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s9yDnLZLDk5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOZYggG0vihTHkmSNt2+iCH","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
