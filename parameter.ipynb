{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms, datasets\n",
    "import optuna\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision.transforms import ColorJitter, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_folder = \"./drive/MyDrive/Upscaling/buildings_low_res\"\n",
    "high_res_folder = \"./drive/MyDrive/Upscaling/buildings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# === creating dataset with all images ===\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, low_res_folder, high_res_folder, transform=None):\n",
    "        self.low_res_images = sorted(os.listdir(low_res_folder))\n",
    "        self.high_res_images = sorted(os.listdir(high_res_folder))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_res_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low_res_image = Image.open(os.path.join(low_res_folder, self.low_res_images[index]))\n",
    "        high_res_image = Image.open(os.path.join(high_res_folder, self.high_res_images[index]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            low_res_image = self.transform(low_res_image)\n",
    "            high_res_image = self.transform(high_res_image)\n",
    "\n",
    "        return low_res_image, high_res_image\n",
    "\n",
    "# transform to tensor\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# original dataset\n",
    "dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n",
    "\n",
    "\n",
    "\n",
    "# === Splitting into train and val sets ===\n",
    "\n",
    "train_size = 0.8  # Proportion of data to be used for training\n",
    "dataset_size = len(dataset)\n",
    "split = int(train_size * dataset_size)\n",
    "train_indices = list(range(split))\n",
    "val_indices = list(range(split, dataset_size))\n",
    "\n",
    "# Create train dataset as a subset of the combined dataset\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "# Create val dataset as a subset of the combined dataset\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "\n",
    "\n",
    "# === Normalization ===\n",
    "normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "train_dataset = [(normalize(image), normalize(target)) for image, target in train_dataset]\n",
    "\n",
    "val_dataset = [(normalize(image), normalize(target)) for image, target in val_dataset]\n",
    "\n",
    "\n",
    "\n",
    "# === train_data augmentation ===\n",
    "\n",
    "# color jitter augmentation for training\n",
    "train_color_jitter = ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "\n",
    "# augmentation factor\n",
    "augmentation_factor = 5\n",
    "\n",
    "# augmented datasets with random color jitter\n",
    "augmented_datasets = []\n",
    "for _ in range(augmentation_factor):\n",
    "    augmented_dataset = []\n",
    "    for image, target in train_dataset:\n",
    "        augmented_dataset.append((train_color_jitter(image), train_color_jitter(target)))\n",
    "    augmented_datasets.append(augmented_dataset)\n",
    "\n",
    "# combine original and augmented datasets\n",
    "combined_datasets = [train_dataset] + augmented_datasets\n",
    "combined_dataset = ConcatDataset(combined_datasets)\n",
    "\n",
    "\n",
    "\n",
    "# === final data loaders ===\n",
    "\n",
    "# Data loaders for train and val sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Number of samples in each set\n",
    "print(f\"Number of training samples originally: {len(train_dataset)}, now augmented to: {len(combined_dataset)}\")\n",
    "print(f\"Number of val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSRCNN(nn.Module):\n",
    "    def __init__(self, d=56, s=12, m=4):\n",
    "        super(FSRCNN, self).__init__()\n",
    "        # Feature Extraction\n",
    "        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.PReLU(d)\n",
    "        # Shrinking\n",
    "        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n",
    "        self.relu2 = nn.PReLU(s)\n",
    "        # Non-linear Mapping\n",
    "        self.mapping = nn.Sequential(*[nn.Sequential(\n",
    "            nn.Conv2d(s, s, kernel_size=3, padding=1),\n",
    "            nn.PReLU(s)\n",
    "        ) for _ in range(m)])\n",
    "        # Expanding\n",
    "        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n",
    "        self.relu3 = nn.PReLU(d)\n",
    "        # Deconvolution\n",
    "        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=3, padding=4, output_padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.mapping(x)\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie das FSRCNN-Modell (wie oben definiert)\n",
    "model = FSRCNN(d=56, s=12, m=4)\n",
    "\n",
    "# Anzahl der in der Parametrsuche verwendeten Epochen\n",
    "num_epochs=5\n",
    "\n",
    "# Definieren Sie den Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Erstellen Sie DataLoader für Ihre Trainings- und Validierungsdaten\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definieren Sie die Optuna-Objective-Funktion\n",
    "def objective(trial):\n",
    "    # Vorschlagen von Hyperparametern\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    d = trial.suggest_int('d', 32, 128)\n",
    "    s = trial.suggest_int('s', 5, 20)\n",
    "    m = trial.suggest_int('m', 2, 8)\n",
    "\n",
    "    # Erstellen Sie das Modell mit den vorgeschlagenen Hyperparametern\n",
    "    model = FSRCNN(d=d, s=s, m=m)\n",
    "\n",
    "    # Definieren Sie den Optimizer mit der vorgeschlagenen Lernrate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            # Null the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Pruning\n",
    "        parameters_to_prune = (\n",
    "            (model.conv1, 'weight'),\n",
    "            (model.conv2, 'weight'),\n",
    "            (model.conv3, 'weight'),\n",
    "        )\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=0.2,\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Inform Optuna of the current loss\n",
    "        trial.report(val_loss/len(val_loader), epoch)\n",
    "\n",
    "        # Implement early stopping\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss/len(val_loader)\n",
    "\n",
    "# Erstellen Sie einen Optuna-Studienobjekt und führen Sie die Optimierung durch\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Konvertieren Sie die Ergebnisse in einen DataFrame\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "# Schreiben Sie den DataFrame in eine Textdatei\n",
    "df.to_csv('optuna_results.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
