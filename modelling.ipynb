{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of models\n",
    "\n",
    "This notebook can only be executed if there already is a folder containing all the low resolution images and a folder containing all the high resolution images.\n",
    "\n",
    "##### Important: When doing a training on new data adjust the upscaling factor in the SRCNN model's bicubic interpolation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "from torchvision.transforms import ColorJitter, Normalize\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading (with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_folder = \"./drive/MyDrive/buildings_low_res\"\n",
    "high_res_folder = \"./drive/MyDrive/buildings\"\n",
    "\n",
    "\n",
    "# === creating dataset with all images ===\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, low_res_folder, high_res_folder, transform=None):\n",
    "        self.low_res_images = sorted(os.listdir(low_res_folder))\n",
    "        self.high_res_images = sorted(os.listdir(high_res_folder))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_res_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low_res_image = Image.open(os.path.join(low_res_folder, self.low_res_images[index]))\n",
    "        high_res_image = Image.open(os.path.join(high_res_folder, self.high_res_images[index]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            low_res_image = self.transform(low_res_image)\n",
    "            high_res_image = self.transform(high_res_image)\n",
    "\n",
    "        return low_res_image, high_res_image\n",
    "\n",
    "# transform to tensor\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# original dataset\n",
    "dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n",
    "\n",
    "\n",
    "\n",
    "# === Splitting into train and val sets ===\n",
    "\n",
    "train_size = 0.8  # Proportion of data to be used for training\n",
    "dataset_size = len(dataset)\n",
    "split = int(train_size * dataset_size)\n",
    "train_indices = list(range(split))\n",
    "val_indices = list(range(split, dataset_size))\n",
    "\n",
    "# Create train dataset as a subset of the combined dataset\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "# Create val dataset as a subset of the combined dataset\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "\n",
    "\n",
    "# === Normalization ===\n",
    "normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "train_dataset = [(normalize(image), normalize(target)) for image, target in train_dataset]\n",
    "\n",
    "val_dataset = [(normalize(image), normalize(target)) for image, target in val_dataset]\n",
    "\n",
    "\n",
    "\n",
    "# === train_data augmentation ===\n",
    "\n",
    "# color jitter augmentation for training\n",
    "train_color_jitter = ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "\n",
    "# augmentation factor\n",
    "augmentation_factor = 5\n",
    "\n",
    "# augmented datasets with random color jitter\n",
    "augmented_datasets = []\n",
    "for _ in range(augmentation_factor):\n",
    "    augmented_dataset = []\n",
    "    for image, target in train_dataset:\n",
    "        augmented_dataset.append((train_color_jitter(image), train_color_jitter(target)))\n",
    "    augmented_datasets.append(augmented_dataset)\n",
    "\n",
    "# combine original and augmented datasets\n",
    "combined_datasets = [train_dataset] + augmented_datasets\n",
    "combined_dataset = ConcatDataset(combined_datasets)\n",
    "\n",
    "\n",
    "\n",
    "# === final data loaders ===\n",
    "\n",
    "# Data loaders for train and val sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Number of samples in each set\n",
    "print(f\"Number of training samples originally: {len(train_dataset)}, now augmented to: {len(combined_dataset)}\")\n",
    "print(f\"Number of val samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSRCNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSRCNN(nn.Module):\n",
    "    def __init__(self, d=56, s=12, m=4):\n",
    "        super(FSRCNN, self).__init__()\n",
    "        # Feature Extraction\n",
    "        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.PReLU(d)\n",
    "        # Shrinking\n",
    "        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n",
    "        self.relu2 = nn.PReLU(s)\n",
    "        # Non-linear Mapping\n",
    "        self.mapping = nn.Sequential(*[nn.Sequential(\n",
    "            nn.Conv2d(s, s, kernel_size=3, padding=1),\n",
    "            nn.PReLU(s)\n",
    "        ) for _ in range(m)])\n",
    "        # Expanding\n",
    "        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n",
    "        self.relu3 = nn.PReLU(d)\n",
    "        # Deconvolution\n",
    "        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=3, padding=4, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.mapping(x)\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "# Training hardware\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# instance of the CNN model\n",
    "model = FSRCNN().to(device)\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 50\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training process\n",
    "for epoch in range(num_epochs):\n",
    "    for input_data, desired_data in train_loader:\n",
    "        # Move input and desired images to device\n",
    "        input_data = input_data.to(device)\n",
    "        desired_data = desired_data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output_images = model(input_data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output_images, desired_data)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training loss per epoch\n",
    "    psnr = 10 * math.log10(1 / loss.item())\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n",
    "\n",
    "# saving the model\n",
    "torch.save(model.state_dict(), \"FSRCNN.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRCNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRCNN model\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.interpolation = nn.Upsample(scale_factor=3, mode='bicubic')\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.interpolation(x)\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "# Training hardware\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# instance of the CNN model\n",
    "model = SRCNN().to(device)\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 40\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training process\n",
    "for epoch in range(num_epochs):\n",
    "    for input_data, desired_data in train_loader:\n",
    "        # Move input and desired images to device\n",
    "        input_data = input_data.to(device)\n",
    "        desired_data = desired_data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output_images = model(input_data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output_images, desired_data)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training loss per epoch\n",
    "    psnr = 10 * math.log10(1 / loss.item())\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n",
    "\n",
    "# saving the model\n",
    "torch.save(model.state_dict(), \"SRCNN.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
