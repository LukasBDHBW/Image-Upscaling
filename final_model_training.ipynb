{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-23T06:59:13.869912Z","iopub.status.busy":"2023-06-23T06:59:13.869493Z","iopub.status.idle":"2023-06-23T06:59:17.911034Z","shell.execute_reply":"2023-06-23T06:59:17.909967Z","shell.execute_reply.started":"2023-06-23T06:59:13.869877Z"},"executionInfo":{"elapsed":8702,"status":"ok","timestamp":1687427997018,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"Evh_r8dmRavT","trusted":true},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","import math\n","from torchvision.transforms import ColorJitter, Normalize\n","from torch.utils.data import ConcatDataset\n","from torch.utils.data import Subset\n","import time\n","from tqdm import tqdm\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VrjMPPdsa8zL"},"source":["### data loading"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["low_res_folder = \"/kaggle/working/dog_low_res\"\n","high_res_folder = \"/kaggle/input/animal-faces/afhq/train/dog\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","\n","base_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# original dataset\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n","\n","\n","\n","# === final data loaders ===\n","\n","# Data loaders for train and val sets\n","batch_size = 64\n","train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Bicubic"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = bicubic().to(device)\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","\n","# saving the model\n","torch.save(model.state_dict(), \"bicubic.pth\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eRnCPEdja_mT"},"source":["### SRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303652,"status":"ok","timestamp":1687426760337,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"0gzlOYjOZVy8","outputId":"985020d4-02da-4d2d-fa4e-06dbf6ef8801"},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x\n","\n","torch.manual_seed(42)\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = SRCNN().to(device)\n","\n","# hyperparameters\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","start_time = time.time()\n","\n","# Training process\n","for epoch in tqdm(range(num_epochs), desc=\"Train\"):\n","    for input_data, desired_data in train_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","end_time = time.time()  # Endzeit in Sekunden seit der Epoche\n","\n","elapsed_time = end_time - start_time  # Verstrichene Zeit in Sekunden\n","print(f\"Verstrichene Zeit: {elapsed_time} Sekunden\")    \n","\n","# saving the model\n","torch.save(model.state_dict(), f\"SRCNN_{num_epochs}.pth\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIwglB9obBWf"},"source":["### FSRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241593,"status":"ok","timestamp":1687427178503,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"61XUL-tBbCVo","outputId":"9314a921-3999-427f-8208-8816e981bb22"},"outputs":[],"source":["class FSRCNN(nn.Module):\n","    def __init__(self, d=56, s=12, m=4):\n","        super(FSRCNN, self).__init__()\n","        # Feature Extraction\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","        # Shrinking\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","        # Non-linear Mapping\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","        # Expanding\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        # Deconvolution\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=5, padding=4, output_padding=4)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x\n","\n","torch.manual_seed(42)\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = FSRCNN().to(device)\n","\n","# hyperparameters\n","learning_rate = 0.001\n","num_epochs = 40\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","import time\n","\n","start_time = time.time()  # Startzeit in Sekunden\n","\n","# Training process\n","for epoch in tqdm(range(num_epochs), desc=\"Train\"):\n","    for input_data, desired_data in train_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","end_time = time.time()  # Endzeit in Sekunden seit der Epoche\n","\n","elapsed_time = end_time - start_time  # Verstrichene Zeit in Sekunden\n","print(f\"Verstrichene Zeit: {elapsed_time} Sekunden\")\n","\n","# saving the model\n","torch.save(model.state_dict(), f\"FSRCNN_{num_epochs}.pth\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOZYggG0vihTHkmSNt2+iCH","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
