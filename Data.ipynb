{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing for human face dataset (no kaggle dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info: The dataset is one big dataset with vertical and horizonal images of different sizes also.\n",
    "So first we split into vertical and horizontal images (we only use vertical ones at the end).\n",
    "Then we take a look at the distribution of image size of the vertical images (they have to be the same size at the end for modelling).\n",
    "We throw away very small images and resize all the other ones to the lowest size remaining.\n",
    "Then from these images we create 4 folders in total - 2 for training and 2 for testing.\n",
    "There is one folder containing the high resolution ground truth images for each and then another with artificially downscaled images.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "horizontal / vertical split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu Ihrem Hauptverzeichnis mit Bildern\n",
    "path = \"C:/Users/a829727/Downloads\" # ===== THIS PATH IS THE ONLY ONE THAT HAS TO BE CHANGED ==== #\n",
    "\n",
    "# Erstellen von Ausgabeordnern\n",
    "horizontal_folder = \"./data/horizontal/\"\n",
    "vertical_folder = \"./data/vertical/\"\n",
    "if not os.path.exists(horizontal_folder):\n",
    "    os.makedirs(horizontal_folder)\n",
    "if not os.path.exists(vertical_folder):\n",
    "    os.makedirs(vertical_folder)\n",
    "\n",
    "# Schleife durch alle Bilder im Verzeichnis und allen Unterordnern\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        # Überprüfen, ob das aktuelle Element eine Bilddatei ist und die Endung .jpg hat\n",
    "        if file.endswith(\".jpg\"):\n",
    "            # Öffnen des Bilds mit der Python Imaging Library (PIL)\n",
    "            img = Image.open(os.path.join(root, file))\n",
    "            # Überprüfen, ob das Bild breiter als hoch ist\n",
    "            if img.width > img.height:\n",
    "                # Bild in horizontalen Ordner kopieren\n",
    "                img.save(os.path.join(horizontal_folder, file))\n",
    "            else:\n",
    "                # Bild in vertikalen Ordner kopieren\n",
    "                img.save(os.path.join(vertical_folder, file))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data distribution insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_dimensions(folder_path):\n",
    "    image_dimensions = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            with Image.open(filepath) as img:\n",
    "                width, height = img.size\n",
    "                image_dimensions.append((width, height))\n",
    "    return image_dimensions\n",
    "\n",
    "def create_histogram(data, title, xlabel, ylabel, direction): \n",
    "    values = [item[direction] for item in data]  # direction 0= witht und 1= hight\n",
    "    plt.hist(values, bins=100, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "folder_path = \"./data/vertical/\"\n",
    "image_dimensions = get_image_dimensions(folder_path)\n",
    "\n",
    "create_histogram(image_dimensions, \"Image Length Histogram\", \"hight\", \"Frequency\",1)\n",
    "create_histogram(image_dimensions, \"Image Width Histogram\", \"Width\", \"Frequency\",0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "throwing away small images under defined threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum Verzeichnis\n",
    "dir_path = \"./data/vertical/\"\n",
    "\n",
    "path_list=[]\n",
    "# Durchlaufe alle Dateien im Verzeichnis\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(dir_path, filename)\n",
    "        # Öffne das Bild und erhalte seine Dimensionen\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "            # Wenn die Dimensionen kleiner sind als gefordert, lösche die Datei\n",
    "            if width < 300 or height < 440:\n",
    "                path_list.append(img_path)\n",
    "                print(f\"Datei {filename} wurde zum Abschuss freigegeben :D\")\n",
    "\n",
    "for path in path_list:\n",
    "    os.remove(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resizing of images to the same size (lower bound) -> needed for CNNs to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum Eingangs- und Ausgangsverzeichnis\n",
    "input_dir_path = \"./data/vertical/\"\n",
    "output_dir_path = \"./data/data_final\"\n",
    "\n",
    "# Falls das Ausgangsverzeichnis nicht existiert, erstelle es\n",
    "if not os.path.exists(output_dir_path):\n",
    "    os.makedirs(output_dir_path)\n",
    "\n",
    "# Durchlaufe alle Dateien im Verzeichnis\n",
    "for filename in os.listdir(input_dir_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(input_dir_path, filename)\n",
    "        # Öffne das Bild und erhalte seine Dimensionen\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "            # Schneide das Bild zu\n",
    "            left = (width - 300)/2\n",
    "            top = max(0, height - 440)  # Falls das Bild weniger als 440 hoch ist, fange oben an\n",
    "            right = (width + 300)/2\n",
    "            bottom = height\n",
    "            img_cropped = img.crop((left, top, right, bottom))\n",
    "            # Speichere das zugeschnittene Bild im Ausgangsverzeichnis\n",
    "            img_cropped.save(os.path.join(output_dir_path, filename))\n",
    "            print(f\"Datei {filename} wurde zugeschnitten und gespeichert.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "folder_paths = ['./data/data_final', './data/downscaled_input']\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # add any other image types if needed\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            if len(img.getbands()) == 1:  # if the image is grayscale, it will have only one color channel\n",
    "                print(f\"Deleting grayscale image: {img_path}\")\n",
    "                img.close()  # close the image file before deleting it\n",
    "                os.remove(img_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting into train / test and downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = \"./data/mensch\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = \"./data/mensch_low_res\"\n",
    "\n",
    "test_low_res_folder = \"./data/mensch_test_low_res\"\n",
    "test_original = \"./data/mensch_test_original\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "if not os.path.exists(test_low_res_folder):\n",
    "    os.makedirs(test_low_res_folder)\n",
    "if not os.path.exists(test_original):\n",
    "    os.makedirs(test_original)\n",
    "\n",
    "\n",
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (60, 88)\n",
    "\n",
    "number_images = len(os.listdir(folder_path))\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "    # Check if the file is an image (optional)\n",
    "    if number<=0.8*number_images:\n",
    "      # Construct the full path to the image file\n",
    "      image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "      # Apply downsampling to the image\n",
    "      downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "      # Save the downscaled image\n",
    "      output_filename = f\"downsampled_{filename}\"\n",
    "      output_path = os.path.join(output_folder_path, output_filename)\n",
    "      downsampled_image.save(output_path)\n",
    "\n",
    "    else:\n",
    "      # Construct the full path to the image file\n",
    "      image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "      image = Image.open(image_path)\n",
    "      image.save(os.path.join(test_original, filename))\n",
    "\n",
    "\n",
    "      # Apply downsampling to the image\n",
    "      downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "      # Save the downscaled image\n",
    "      output_filename = f\"downsampled_{filename}\"\n",
    "      output_path = os.path.join(test_low_res_folder, output_filename)\n",
    "      downsampled_image.save(output_path)\n",
    "\n",
    "      os.remove(os.path.join(folder_path, filename))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle dataset processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info: Kaggle datasets we use are split into train and test data by default (validation split is done via model training later and not saved to disk into seperate folders), same size and all RGB. So preprocessing is just creating the low resolution data for model input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating low resolution input dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = \"/kaggle/input/animal-faces/afhq/train/dog\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = \"/kaggle/working/dog_low_res\"\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "\n",
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (128, 128)\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "  # Construct the full path to the image file\n",
    "  image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "  # Apply downsampling to the image\n",
    "  downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "  # Save the downscaled image\n",
    "  output_filename = f\"downsampled_{filename}\"\n",
    "  output_path = os.path.join(output_folder_path, output_filename)\n",
    "  downsampled_image.save(output_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating low resolution input dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = \"/kaggle/input/animal-faces/afhq/train/dog\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = \"/kaggle/working/dog_low_res\"\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "\n",
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (128, 128)\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "  # Construct the full path to the image file\n",
    "  image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "  # Apply downsampling to the image\n",
    "  downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "  # Save the downscaled image\n",
    "  output_filename = f\"downsampled_{filename}\"\n",
    "  output_path = os.path.join(output_folder_path, output_filename)\n",
    "  downsampled_image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "folder_paths = ['./data/data_final', './data/downscaled_input']\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # add any other image types if needed\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            if len(img.getbands()) == 1:  # if the image is grayscale, it will have only one color channel\n",
    "                print(f\"Deleting grayscale image: {img_path}\")\n",
    "                img.close()  # close the image file before deleting it\n",
    "                os.remove(img_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
