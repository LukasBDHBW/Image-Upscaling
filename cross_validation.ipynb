{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1687459037407,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"Evh_r8dmRavT"},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","import math\n","from torchvision.transforms import ColorJitter, Normalize\n","from torch.utils.data import ConcatDataset\n","from torch.utils.data import Subset\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import DataLoader, random_split\n","import numpy as np\n","from tqdm import tqdm\n","\n","# torch_xla can be installed and imported for TPU usage\n","# import torch_xla\n","# import torch_xla.core.xla_model as xm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18864,"status":"ok","timestamp":1687458488976,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"jfnm7EnuMCUL","outputId":"7355f7a5-4268-4405-ba06-85646c2bbfe5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6766,"status":"ok","timestamp":1687458495733,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"8BjeNxVYHef6"},"outputs":[],"source":["low_res_folder = \"./drive/MyDrive/Upscaling/mensch_low_res\"\n","high_res_folder = \"./drive/MyDrive/Upscaling/mensch\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","# transform to tensor & normalize\n","normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","\n","base_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# original dataset\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### bicubic"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = bicubic().to(device)\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","# Validating the model (on validation data)\n","for input_data, desired_data in val_loader:\n","    # Move input and desired images to device\n","    input_data = input_data.to(device)\n","    desired_data = desired_data.to(device)\n","\n","    # Forward pass\n","    output_images = model(input_data)\n","\n","    # Calculate loss\n","    loss = criterion(output_images, desired_data)\n","\n","# Print training loss per epoch\n","psnr = 10 * math.log10(1 / loss.item())\n","\n","print(f\"Loss (validation): {loss.item():.4f}, PSNR (validation): {psnr}\")\n","\n","\n","# saving the model\n","torch.save(model.state_dict(), \"bicubic.pth\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eRnCPEdja_mT"},"source":["### SRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gzlOYjOZVy8"},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIwglB9obBWf"},"source":["### FSRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687459044090,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"r41JedVuIaFM"},"outputs":[],"source":["class FSRCNN(nn.Module):\n","    def __init__(self, d=56, s=12, m=4):\n","        super(FSRCNN, self).__init__()\n","        # Feature Extraction\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","        # Shrinking\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","        # Non-linear Mapping\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","        # Expanding\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        # Deconvolution\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=5, padding=4, output_padding=4)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ESPCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ESPCN(nn.Module):\n","    def __init__(self, upscale_factor=4, num_channels=3):\n","        super(ESPCN, self).__init__()\n","        self.upscale_factor = upscale_factor\n","        \n","        # Feature Extraction\n","        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=5, padding=2)\n","        self.relu1 = nn.ReLU()\n","        \n","        # Sub-Pixel Convolution\n","        self.conv2 = nn.Conv2d(64, num_channels * upscale_factor ** 2, kernel_size=3, padding=1)\n","        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n","        self.relu2 = nn.ReLU()\n","    \n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.pixel_shuffle(self.conv2(x))\n","        x = self.relu2(x)\n","        return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### cross validation of bicubic interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","\n","# Cross-validation setup\n","num_folds = 5\n","fold_len = np.floor(len(indices) / num_folds).astype('int')\n","\n","batch_size = 16\n","total_psnr = 0\n","\n","for fold in range(num_folds):\n","\n","    # Calculate start and end indices for validation data\n","    val_start = fold * fold_len\n","    val_end = (fold + 1) * fold_len\n","\n","\n","    val_indices = indices[val_start:val_end]\n","\n","\n","    # Normalization transformation\n","\n","    val_transform = transforms.Compose([\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    val_dataset = Subset(dataset, val_indices)\n","    val_dataset.transform = val_transform\n","\n","    # Create train and validation data loaders\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    # Training hardware\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # instance of the CNN model\n","    model = bicubic().to(device)\n","\n","    # loss function and optimizer\n","    criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","\n","    # Validating the model (on validation data)\n","    val_loss = 0\n","    number_batches = 0\n","    for input_data, desired_data in val_loader:\n","        number_batches += 1\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        val_loss += loss.item()\n","\n","    val_loss_avg = val_loss / number_batches\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / val_loss_avg)\n","    total_psnr += psnr\n","\n","    print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","\n","total_psnr = total_psnr/num_folds\n","print(f\"Total PSNR:{total_psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### cross validation training for SRCNN and FSRCNN\n","##### (change model in the cell below to training target)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374252,"status":"ok","timestamp":1687460343759,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"61XUL-tBbCVo","outputId":"d4577f02-c024-4aa1-aaa6-010bf81ce6fe"},"outputs":[],"source":["dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","\n","# Cross-validation setup\n","num_folds = 5\n","fold_len = np.floor(len(indices) / num_folds).astype('int')\n","\n","batch_size = 16\n","total_psnr = 0\n","\n","# instance of the CNN model\n","model = FSRCNN().to(device) ### CHANGE MODEL HERE ###\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","graph_values_folds = []\n","\n","for fold in range(num_folds):\n","\n","    graph_values_epochs=[]\n","    # Initialize train and validation indices\n","    # Calculate start and end indices for validation data\n","    val_start = fold * fold_len\n","    val_end = (fold + 1) * fold_len\n","\n","    # Split indices into train and validation sets\n","    val_indices = indices[val_start:val_end]\n","    train_indices = indices[:val_start] + indices[val_end:]\n","\n","\n","    # Create train and validation datasets\n","    train_dataset = Subset(dataset, train_indices)\n","\n","    val_dataset = Subset(dataset, val_indices)\n","\n","    # Create train and validation data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    \n","    # hyperparameters\n","    learning_rate = 0.001\n","    num_epochs = 50\n","    early_stopping_patience = 3\n","    best_val_loss = float('inf')\n","    epochs_without_improvement = 0\n","\n","    # loss function and optimizer\n","    criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training process\n","    print(\"hi\")\n","    psnr_fold = 0\n","    for epoch in range(num_epochs):\n","        for input_data, desired_data in train_loader:\n","            # Move input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","\n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Print training loss per epoch\n","        psnr = 10 * math.log10(1 / loss.item())\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","        # Validating the model (on validation data)\n","        val_loss = 0\n","        number_batches = 0\n","        for input_data, desired_data in val_loader:\n","            number_batches += 1\n","            # Move input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","            val_loss += loss.item()\n","\n","        val_loss_avg = val_loss / number_batches\n","\n","        # Print training loss per epoch\n","        psnr = 10 * math.log10(1 / val_loss_avg)\n","        psnr_fold += psnr\n","\n","        print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","        graph_values_epochs.append(val_loss_avg)\n","\n","        # Check for early stopping\n","        if val_loss_avg < best_val_loss:\n","            best_val_loss = val_loss_avg\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","            if epochs_without_improvement == early_stopping_patience:\n","                print(\"Early stopping triggered. No improvement in validation loss.\")\n","                total_psnr += psnr_fold / (epoch+1)\n","                break\n","    total_psnr += psnr_fold / num_epochs\n","    graph_values_folds.append(graph_values_epochs)\n","\n","total_psnr = total_psnr/num_folds\n","print(f\"Total PSNR:{total_psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### plot for PSNR over epochs for different folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s9yDnLZLDk5"},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.offline as pyo\n","import numpy as np\n","\n","data = [[1, 2, 3, 4], [2, 4, 6, 8, 10], [3, 6, 9]]\n","\n","fig = go.Figure()\n","\n","# Calculate the average of all sublists\n","average_line = np.mean(data, axis=0)[:min(len(sublist) for sublist in data)]\n","\n","for sublist in data:\n","    fig.add_trace(go.Scatter(x=list(range(len(sublist))), y=sublist, mode='lines'))\n","\n","fig.add_trace(go.Scatter(x=list(range(len(average_line))), y=average_line, mode='lines', name='Average'))\n","\n","fig.update_xaxes(title_text='Number of epochs')\n","fig.update_yaxes(title_text='PSNR')\n","\n","pyo.plot(fig, filename='PSNR_over_epochs_folds.html')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
