{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1687459037407,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"Evh_r8dmRavT"},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","import math\n","from torchvision.transforms import ColorJitter, Normalize\n","from torch.utils.data import ConcatDataset\n","from torch.utils.data import Subset\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import DataLoader, random_split\n","import numpy as np\n","from tqdm import tqdm\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfnm7EnuMCUL","executionInfo":{"status":"ok","timestamp":1687458488976,"user_tz":-120,"elapsed":18864,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"}},"outputId":"7355f7a5-4268-4405-ba06-85646c2bbfe5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8BjeNxVYHef6","executionInfo":{"status":"ok","timestamp":1687458495733,"user_tz":-120,"elapsed":6766,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"}}},"outputs":[],"source":["low_res_folder = \"./drive/MyDrive/Upscaling/mensch_low_res\"\n","high_res_folder = \"./drive/MyDrive/Upscaling/mensch\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","# transform to tensor & normalize\n","normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","\n","base_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","# original dataset\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)"]},{"cell_type":"markdown","metadata":{"id":"eRnCPEdja_mT"},"source":["### SRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gzlOYjOZVy8"},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = SRCNN().to(device)\n","\n","# hyperparameters\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training process\n","for epoch in range(num_epochs):\n","    for input_data, desired_data in train_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / loss.item())\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","    # Validating the model (on validation data)\n","    for input_data, desired_data in val_loader:\n","        # Move input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","\n","    # Print training loss per epoch\n","    psnr = 10 * math.log10(1 / loss.item())\n","\n","    print(f\"Loss (validation): {loss.item():.4f}, PSNR (validation): {psnr}\")\n","\n","# saving the model\n","torch.save(model.state_dict(), \"SRCNN.pth\")"]},{"cell_type":"markdown","metadata":{"id":"IIwglB9obBWf"},"source":["### FSRCNN"]},{"cell_type":"code","source":["class FSRCNN(nn.Module):\n","    def __init__(self, d=56, s=12, m=4):\n","        super(FSRCNN, self).__init__()\n","        # Feature Extraction\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","        # Shrinking\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","        # Non-linear Mapping\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","        # Expanding\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        # Deconvolution\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=5, padding=4, output_padding=4)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x"],"metadata":{"id":"r41JedVuIaFM","executionInfo":{"status":"ok","timestamp":1687459044090,"user_tz":-120,"elapsed":7,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374252,"status":"ok","timestamp":1687460343759,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"61XUL-tBbCVo","outputId":"d4577f02-c024-4aa1-aaa6-010bf81ce6fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["hi\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","Epoch [1/1], Loss: 0.0835, PSNR: 10.784431398641726\n","Loss (validation): 0.0705, PSNR (validation): 11.515995725847901\n","hi\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","Epoch [1/1], Loss: 0.0670, PSNR: 11.742103637982591\n","Loss (validation): 0.0682, PSNR (validation): 11.6623312524994\n","hi\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","Epoch [1/1], Loss: 0.0704, PSNR: 11.522969217833621\n","Loss (validation): 0.0762, PSNR (validation): 11.180147565564756\n","hi\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","Epoch [1/1], Loss: 0.0550, PSNR: 12.599650410638079\n","Loss (validation): 0.0636, PSNR (validation): 11.964174490677898\n","hi\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","Epoch [1/1], Loss: 0.0693, PSNR: 11.593206301445761\n","Loss (validation): 0.0724, PSNR (validation): 11.403654721979596\n","Total PSNR:11.54526075131391\n"]}],"source":["# Assuming that dataset is your dataset\n","dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","\n","# Cross-validation setup\n","num_folds = 5\n","fold_len = np.floor(len(indices)/num_folds).astype('int')\n","\n","batch_size = 16\n","total_psnr = 0\n","for fold in range(num_folds):\n","    # Initialize train and validation samplers\n","    train_indices = indices[:fold*fold_len] + indices[(fold+1)*fold_len:]\n","    val_indices = indices[fold*fold_len:(fold+1)*fold_len]\n","\n","    train_sampler = SubsetRandomSampler(train_indices)\n","    val_sampler = SubsetRandomSampler(val_indices)\n","\n","    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n","\n","    # Training hardware\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # instance of the CNN model\n","    model = FSRCNN().to(device)\n","\n","    # hyperparameters\n","    learning_rate = 0.001\n","    num_epochs = 1\n","\n","    # loss function and optimizer\n","    criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training process\n","    print(\"hi\")\n","    for epoch in range(num_epochs):\n","        a=0\n","        for input_data, desired_data in train_loader:\n","            a+=1\n","            print(a)\n","            # Move input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","\n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Print training loss per epoch\n","        psnr = 10 * math.log10(1 / loss.item())\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","        # Validating the model (on validation data)\n","        val_loss = 0\n","        number_batches = 0\n","        for input_data, desired_data in val_loader:\n","            number_batches += 1\n","            # Move input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","            val_loss += loss.item()\n","\n","        val_loss_avg = val_loss / number_batches\n","\n","        # Print training loss per epoch\n","        psnr = 10 * math.log10(1 / val_loss_avg)\n","        total_psnr += psnr\n","\n","        print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","\n","total_psnr = total_psnr/num_folds\n","print(f\"Total PSNR:{total_psnr}\")"]},{"cell_type":"code","source":["range(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKvxh8vpbpBC","executionInfo":{"status":"ok","timestamp":1687459638331,"user_tz":-120,"elapsed":398,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"}},"outputId":"ac5f5edc-caff-40ba-c964-6d3511ad2f50"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["range(0, 5)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"yrLNqyDyJt2P"},"source":["### Bicubic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1074,"status":"ok","timestamp":1687427876086,"user":{"displayName":"Marcus","userId":"05894618993451037890"},"user_tz":-120},"id":"An0Ri4gtJZbC","outputId":"b5d806d6-c5f7-4dbe-f07a-69012eb94eef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss (validation): 0.0114, PSNR (validation): 19.41890646298794\n"]}],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n","\n","# Training hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# instance of the CNN model\n","model = bicubic().to(device)\n","\n","# loss function and optimizer\n","criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","# Validating the model (on validation data)\n","for input_data, desired_data in val_loader:\n","    # Move input and desired images to device\n","    input_data = input_data.to(device)\n","    desired_data = desired_data.to(device)\n","\n","    # Forward pass\n","    output_images = model(input_data)\n","\n","    # Calculate loss\n","    loss = criterion(output_images, desired_data)\n","\n","# Print training loss per epoch\n","psnr = 10 * math.log10(1 / loss.item())\n","\n","print(f\"Loss (validation): {loss.item():.4f}, PSNR (validation): {psnr}\")\n","\n","\n","# saving the model\n","torch.save(model.state_dict(), \"bicubic.pth\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s9yDnLZLDk5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}