{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Notebook for testing all models\n","#### (all adapted to dog dataset)\n","#### => currently all blocks for running tests on a single image or only calculating PSNR are commented out\n","#### => all not commented out blocks are needed to run a full test (which includes running all models on all the testing data and saving the images as well as calculating PSNR)\n","#### => important: when upscaling ratio changes all models have to be changed to new upscaling ratio and also the downscaling size\n","####    \n","####    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### import statements"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:17.144929Z","iopub.status.busy":"2023-06-24T17:40:17.144443Z","iopub.status.idle":"2023-06-24T17:40:20.223614Z","shell.execute_reply":"2023-06-24T17:40:20.222328Z","shell.execute_reply.started":"2023-06-24T17:40:17.144893Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import os\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import Normalize\n","import math\n","import time"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### create low res version of all test images as input test data (only neede for dog dataset since test data is seperate kaggle folder; for human dataset train/test split is done manually in the data notebook, where low res is created for everything already)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:20.225964Z","iopub.status.busy":"2023-06-24T17:40:20.225366Z","iopub.status.idle":"2023-06-24T17:40:25.807387Z","shell.execute_reply":"2023-06-24T17:40:25.806228Z","shell.execute_reply.started":"2023-06-24T17:40:20.225933Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'def downsample_image(image_path, output_size):\\n    # Open the image\\n    image = Image.open(image_path)\\n\\n    # Perform downsampling using bicubic interpolation\\n    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\\n\\n    return downscaled_image\\n\\n# Folder path containing the images\\nfolder_path = \"/kaggle/input/animal-faces/afhq/val/dog\"\\n\\n# Defining folder for downscaled images serving for input for modelling (&upscaling)\\noutput_folder_path = \"/kaggle/working/dog_low_res\"\\nif not os.path.exists(output_folder_path):\\n    os.makedirs(output_folder_path)\\n\\n\\n# Output size for downsampling\\noutput_size = (128, 128)\\n\\n# Iterate over the files in the folder\\nfor number, filename in enumerate(os.listdir(folder_path)):\\n\\n  # Construct the full path to the image file\\n  image_path = os.path.join(folder_path, filename)\\n\\n  # Apply downsampling to the image\\n  downsampled_image = downsample_image(image_path, output_size)\\n\\n  # Save the downscaled image\\n  output_filename = f\"downsampled_{filename}\"\\n  output_path = os.path.join(output_folder_path, output_filename)\\n  downsampled_image.save(output_path)\\n'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["def downsample_image(image_path, output_size):\n","    image = Image.open(image_path)\n","\n","    # Downsampling using bicubic interpolation\n","    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n","\n","    return downscaled_image\n","\n","# Folder with high resolution test images\n","folder_path = \"/kaggle/input/animal-faces/afhq/val/dog\"\n","\n","# Creating folder for downscaled images\n","output_folder_path = \"/kaggle/working/dog_low_res\"\n","if not os.path.exists(output_folder_path):\n","    os.makedirs(output_folder_path)\n","\n","\n","# Output size for downscaling\n","output_size = (128, 128)\n","\n","# Loop over all files in the high res folder\n","for number, filename in enumerate(os.listdir(folder_path)):\n","\n","  image_path = os.path.join(folder_path, filename)\n","\n","  # Downscaling each image\n","  downsampled_image = downsample_image(image_path, output_size)\n","\n","  # Saving downscaled image\n","  output_filename = f\"downsampled_{filename}\"\n","  output_path = os.path.join(output_folder_path, output_filename)\n","  downsampled_image.save(output_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### using same data loaders built for training process to load data for testing"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:25.810679Z","iopub.status.busy":"2023-06-24T17:40:25.808840Z","iopub.status.idle":"2023-06-24T17:40:25.822094Z","shell.execute_reply":"2023-06-24T17:40:25.820524Z","shell.execute_reply.started":"2023-06-24T17:40:25.810649Z"},"trusted":true},"outputs":[],"source":["low_res_folder = \"/kaggle/working/dog_low_res\"\n","high_res_folder = \"/kaggle/input/animal-faces/afhq/val/dog\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","# transformation to tensor\n","base_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# dataset consists of pairs of high res / low res images\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)\n","\n","batch_size = 64 # batch size not relevant for testing\n","test_loader = DataLoader(dataset, batch_size=batch_size)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### defining structure of all models (needed since saving a model only saves the weights)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:25.825401Z","iopub.status.busy":"2023-06-24T17:40:25.824611Z","iopub.status.idle":"2023-06-24T17:40:25.846270Z","shell.execute_reply":"2023-06-24T17:40:25.844931Z","shell.execute_reply.started":"2023-06-24T17:40:25.825362Z"},"trusted":true},"outputs":[],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:25.848267Z","iopub.status.busy":"2023-06-24T17:40:25.847825Z","iopub.status.idle":"2023-06-24T17:40:25.860145Z","shell.execute_reply":"2023-06-24T17:40:25.858725Z","shell.execute_reply.started":"2023-06-24T17:40:25.848228Z"},"trusted":true},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:25.861927Z","iopub.status.busy":"2023-06-24T17:40:25.861503Z","iopub.status.idle":"2023-06-24T17:40:25.880412Z","shell.execute_reply":"2023-06-24T17:40:25.878991Z","shell.execute_reply.started":"2023-06-24T17:40:25.861891Z"},"trusted":true},"outputs":[],"source":["# Load the trained model\n","class FSRCNN(nn.Module):\n","    def __init__(self, d=116, s=15, m=3):\n","        super(FSRCNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        \n","        # Deconvolution for upscaling to desired size\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=4, padding=4, output_padding=3)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["class ESPCN(nn.Module):\n","    def __init__(self, upscale_factor=4, num_channels=3):\n","        super(ESPCN, self).__init__()\n","        self.upscale_factor = upscale_factor\n","        \n","        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=5, padding=2)\n","        self.relu1 = nn.ReLU()\n","        \n","        # Subpixel convolution with pixle shuffle for upscaling to desired size\n","        self.conv2 = nn.Conv2d(64, num_channels * upscale_factor ** 2, kernel_size=3, padding=1)\n","        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n","        self.relu2 = nn.ReLU()\n","    \n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.pixel_shuffle(self.conv2(x))\n","        x = self.relu2(x)\n","        return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ==========================================\n","### Important: There are few cells which are commented out here, only comment them in when wanting to test the model on single image or calculate PSNR only without saving any images. If you want to test the models on all testing data with PSNR output and output images in a good folder structure, please skip the commented out cells and scroll further down :) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### loading a saved model (only run the cell of one modell at a time here)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:34:58.777948Z","iopub.status.busy":"2023-06-24T17:34:58.777592Z","iopub.status.idle":"2023-06-24T17:34:58.793280Z","shell.execute_reply":"2023-06-24T17:34:58.792358Z","shell.execute_reply.started":"2023-06-24T17:34:58.777922Z"},"trusted":true},"outputs":[],"source":["# model = bicubic()\n","# model.load_state_dict(torch.load(\"/kaggle/input/bicubic/bicubic.pth\", map_location=torch.device('cpu')))\n","# model.eval()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:40:25.882391Z","iopub.status.busy":"2023-06-24T17:40:25.882083Z","iopub.status.idle":"2023-06-24T17:40:25.965473Z","shell.execute_reply":"2023-06-24T17:40:25.964138Z","shell.execute_reply.started":"2023-06-24T17:40:25.882365Z"},"trusted":true},"outputs":[],"source":["# model = FSRCNN()\n","# model.load_state_dict(torch.load(\"/kaggle/input/final-models/FSRCNN_18.pth\", map_location=torch.device('cpu')))\n","# model.eval()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# model = SRCNN()\n","# model.load_state_dict(torch.load(\"/kaggle/input/final-models/SRCNN_13.pth\", map_location=torch.device('cpu')))\n","# model.eval()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# model = ESPCN()\n","# model.load_state_dict(torch.load(\"/kaggle/input/final-models/ESPCN_13.pth\", map_location=torch.device('cpu')))\n","# model.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### test the model on a single defined image"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:33:12.798010Z","iopub.status.busy":"2023-06-24T17:33:12.797606Z","iopub.status.idle":"2023-06-24T17:33:12.998599Z","shell.execute_reply":"2023-06-24T17:33:12.997647Z","shell.execute_reply.started":"2023-06-24T17:33:12.797944Z"},"trusted":true},"outputs":[],"source":["# # Preprocess the test image\n","# path = \"/kaggle/working/dog_low_res\"\n","# filename = \"\" # write a valid filename here\n","# test_image_path = path+filename\n","# test_image = Image.open(test_image_path)\n","# transform = transforms.Compose([\n","#     transforms.ToTensor()\n","# ])\n","# test_image = transform(test_image).unsqueeze(0)\n","\n","# # Apply the model to the test image\n","# with torch.no_grad():\n","#     output_image = model(test_image)\n","\n","# # Convert the output tensor to an image\n","# output_image = output_image.squeeze(0)\n","# output_image = transforms.ToPILImage()(output_image)\n","\n","# # Save the output image\n","# output_image.save(f\"./data/Human/Up/upscaled_{filename}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### calculate testing PSNR only (no images will be saved)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-06-24T17:35:13.888621Z","iopub.status.busy":"2023-06-24T17:35:13.888051Z","iopub.status.idle":"2023-06-24T17:35:19.157510Z","shell.execute_reply":"2023-06-24T17:35:19.156606Z","shell.execute_reply.started":"2023-06-24T17:35:13.888589Z"},"trusted":true},"outputs":[],"source":["# import time\n","# test_loss = 0\n","# number_batches = 0\n","# criterion = nn.MSELoss()\n","# device = torch.device(\"cpu\")\n","\n","# start_time = time.time()\n","# for input_data, desired_data in test_loader:\n","#     with torch.no_grad():\n","#         number_batches += 1\n","#         print(number_batches)\n","\n","#         input_data = input_data.to(device)\n","#         desired_data = desired_data.to(device)\n","\n","#         # Forward pass\n","#         output_images = model(input_data)\n","\n","#         # Calculate loss\n","#         loss = criterion(output_images, desired_data)\n","#         test_loss += loss.item()\n","\n","# end_time = time.time()  \n","\n","# elapsed_time = end_time - start_time  \n","# print(f\"Duration (total): {elapsed_time} seconds, duration per file: {elapsed_time/len(dataset)} seconds\")\n","\n","# test_loss_avg = test_loss / number_batches\n","\n","# psnr = 10 * math.log10(1 / test_loss_avg)\n","\n","# print(f\"Loss: {test_loss_avg:.4f}, PSNR: {psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ==========================================\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### apply all models to all the tesing data (saves upscaled images and calculates PSNR)\n","##### down below first a folder structure is created, then each model has two cells - one for loading the model and one for applying it to all test data (therefore the application cells are similar for each model, advantage is that you don't have to change anything when running the cells and can test all models at once by running all cells below)\n","#####"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### creating folder structure for output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'number_batches = 0\\ndevice = torch.device(\"cpu\")\\n\\nimg_comparison_folder = \"./data/Human/img_comparison\"\\n\\nif not os.path.exists(img_comparison_folder):\\n    os.makedirs(img_comparison_folder)\\n\\nstart_time = time.time()\\nfor input_data, desired_data in test_loader:\\n    with torch.no_grad():\\n        number_batches += 1\\n        if not os.path.exists(f\"./data/Human/img_comparison/batch_{number_batches}\"):\\n            os.makedirs(f\"./data/Human/img_comparison/batch_{number_batches}\")\\n\\n        # Move input and desired images to device\\n        input_data = input_data.to(device)\\n        desired_data = desired_data.to(device)\\n            \\n        # saving low res images from the same batch into the same folder\\n        for number, image in enumerate(input_data):\\n            image = image.squeeze(0)\\n            image = transforms.ToPILImage()(image)\\n            image.save(f\"./data/Human/img_comparison/batch_{number_batches}/{number}_input.jpg\")\\n            \\n        # saving original images from the same batch into the same folder\\n        for number, image in enumerate(desired_data):\\n            image = image.squeeze(0)\\n            image = transforms.ToPILImage()(image)\\n            image.save(f\"./data/Human/img_comparison/batch_{number_batches}/{number}_original.jpg\")\\n\\nend_time = time.time()  # Endzeit in Sekunden seit der Epoche\\n\\nelapsed_time = end_time - start_time  # Verstrichene Zeit in Sekunden\\nprint(f\"Verstrichene Zeit: {elapsed_time} Sekunden\")\\n'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["number_batches = 0\n","device = torch.device(\"cpu\")\n","\n","img_comparison_folder = \"/kaggle/working/img_comparison\"\n","\n","if not os.path.exists(img_comparison_folder):\n","    os.makedirs(img_comparison_folder)\n","\n","start_time = time.time() # start timer\n","for input_data, desired_data in test_loader:\n","    with torch.no_grad():\n","        number_batches += 1\n","\n","        # creating a folder for the current batch (decision was made to split up file structure into batch folders)\n","        if not os.path.exists(f\"/kaggle/working/img_comparison/batch_{number_batches}\"):\n","            os.makedirs(f\"/kaggle/working/img_comparison/batch_{number_batches}\")\n","\n","        # input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","            \n","        # saving low res images from the same batch into the current batch folder\n","        for number, image in enumerate(input_data):\n","            image = image.squeeze(0)\n","            image = transforms.ToPILImage()(image)\n","            image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_input.jpg\")\n","            \n","        # saving original images from the same batch into the same folder\n","        for number, image in enumerate(desired_data):\n","            image = image.squeeze(0)\n","            image = transforms.ToPILImage()(image)\n","            image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_original.jpg\")\n","\n","end_time = time.time()  # stop timer\n","\n","elapsed_time = end_time - start_time  # calculate time\n","print(f\"Time needed: {elapsed_time} seconds\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### bicubic"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["bicubic(\n","  (interpolation): Upsample(scale_factor=3.0, mode='bicubic')\n",")"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["model = bicubic()\n","model.load_state_dict(torch.load(\"/kaggle/input/final-models/bicubic.pth\", map_location=torch.device('cpu')))\n","model.eval()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Verstrichene Zeit: 358.05539178848267 Sekunden\n","Loss: 0.0011, PSNR: 29.57149595113906\n"]}],"source":["test_loss = 0\n","number_batches = 0\n","criterion = nn.MSELoss()\n","device = torch.device(\"cpu\")\n","\n","img_comparison_folder = \"/kaggle/working/img_comparison\"\n","\n","if not os.path.exists(img_comparison_folder):\n","    os.makedirs(img_comparison_folder)\n","start_time = time.time() # start timer\n","for input_data, desired_data in test_loader:\n","    with torch.no_grad():\n","        number_batches += 1\n","\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        test_loss += loss.item()\n","        \n","        # saving the images\n","        for number, output_image in enumerate(output_images):\n","            output_image = output_image.squeeze(0)\n","            output_image = transforms.ToPILImage()(output_image)\n","            output_image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_upscaled_bicubic.jpg\")\n","            \n","        \n","end_time = time.time()  # stop timer\n","\n","elapsed_time = end_time - start_time  # calculate time\n","print(f\"Needed time: {elapsed_time} seconds\")\n","test_loss_avg = test_loss / number_batches\n","\n","# Print test loss\n","psnr = 10 * math.log10(1 / test_loss_avg)\n","\n","print(f\"Loss: {test_loss_avg:.4f}, PSNR: {psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### SRCNN"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["SRCNN(\n","  (interpolation): Upsample(scale_factor=3.0, mode='bicubic')\n","  (conv1): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n","  (relu1): ReLU()\n","  (conv2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","  (relu2): ReLU()\n","  (conv3): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (relu3): ReLU()\n",")"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["model = SRCNN()\n","model.load_state_dict(torch.load(\"/kaggle/input/final-models/SRCNN_13.pth\", map_location=torch.device('cpu')))\n","model.eval()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["test_loss = 0\n","number_batches = 0\n","criterion = nn.MSELoss()\n","device = torch.device(\"cpu\")\n","\n","img_comparison_folder = \"/kaggle/working/img_comparison\"\n","\n","if not os.path.exists(img_comparison_folder):\n","    os.makedirs(img_comparison_folder)\n","start_time = time.time() # start timer\n","for input_data, desired_data in test_loader:\n","    with torch.no_grad():\n","        number_batches += 1\n","\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        test_loss += loss.item()\n","        \n","        # saving the images\n","        for number, output_image in enumerate(output_images):\n","            output_image = output_image.squeeze(0)\n","            output_image = transforms.ToPILImage()(output_image)\n","            output_image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_upscaled_SRCNN.jpg\")\n","            \n","        \n","end_time = time.time()  # stop timer\n","\n","elapsed_time = end_time - start_time  # calculate time\n","print(f\"Needed time: {elapsed_time} seconds\")\n","test_loss_avg = test_loss / number_batches\n","\n","# Print test loss\n","psnr = 10 * math.log10(1 / test_loss_avg)\n","\n","print(f\"Loss: {test_loss_avg:.4f}, PSNR: {psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### FSRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = FSRCNN()\n","model.load_state_dict(torch.load(\"/kaggle/input/final-models/FSRCNN_18.pth\", map_location=torch.device('cpu')))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_loss = 0\n","number_batches = 0\n","criterion = nn.MSELoss()\n","device = torch.device(\"cpu\")\n","\n","img_comparison_folder = \"/kaggle/working/img_comparison\"\n","\n","if not os.path.exists(img_comparison_folder):\n","    os.makedirs(img_comparison_folder)\n","start_time = time.time() # start timer\n","for input_data, desired_data in test_loader:\n","    with torch.no_grad():\n","        number_batches += 1\n","\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        test_loss += loss.item()\n","        \n","        # saving the images\n","        for number, output_image in enumerate(output_images):\n","            output_image = output_image.squeeze(0)\n","            output_image = transforms.ToPILImage()(output_image)\n","            output_image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_upscaled_FSRCNN.jpg\")\n","            \n","        \n","end_time = time.time()  # stop timer\n","\n","elapsed_time = end_time - start_time  # calculate time\n","print(f\"Needed time: {elapsed_time} seconds\")\n","test_loss_avg = test_loss / number_batches\n","\n","# Print test loss\n","psnr = 10 * math.log10(1 / test_loss_avg)\n","\n","print(f\"Loss: {test_loss_avg:.4f}, PSNR: {psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ESPCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = ESPCN()\n","model.load_state_dict(torch.load(\"/kaggle/input/final-models/ESPCN_13.pth\", map_location=torch.device('cpu')))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_loss = 0\n","number_batches = 0\n","criterion = nn.MSELoss()\n","device = torch.device(\"cpu\")\n","\n","img_comparison_folder = \"/kaggle/working/img_comparison\"\n","\n","if not os.path.exists(img_comparison_folder):\n","    os.makedirs(img_comparison_folder)\n","start_time = time.time() # start timer\n","for input_data, desired_data in test_loader:\n","    with torch.no_grad():\n","        number_batches += 1\n","\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        test_loss += loss.item()\n","        \n","        # saving the images\n","        for number, output_image in enumerate(output_images):\n","            output_image = output_image.squeeze(0)\n","            output_image = transforms.ToPILImage()(output_image)\n","            output_image.save(f\"/kaggle/working/img_comparison/batch_{number_batches}/{number}_upscaled_ESPCN.jpg\")\n","            \n","        \n","end_time = time.time()  # stop timer\n","\n","elapsed_time = end_time - start_time  # calculate time\n","print(f\"Needed time: {elapsed_time} seconds\")\n","test_loss_avg = test_loss / number_batches\n","\n","# Print test loss\n","psnr = 10 * math.log10(1 / test_loss_avg)\n","\n","print(f\"Loss: {test_loss_avg:.4f}, PSNR: {psnr}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
