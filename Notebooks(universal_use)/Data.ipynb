{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing for human face dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preperation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the Human Folder from the Kaggle download in this directory\n",
    "start_dir=\"../human_process_results/data/Humans\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(dir):\n",
    "    # store hashes\n",
    "    hashes = {}\n",
    "\n",
    "    # Iterate through all images in the directory\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            filepath = os.path.join(dir, filename)\n",
    "            \n",
    "            # Open image and convert to hash\n",
    "            with Image.open(filepath) as img:\n",
    "                tmp_img = img.resize((10, 10), Image.ANTIALIAS)\n",
    "                hash = hashlib.sha1(tmp_img.tobytes()).hexdigest()\n",
    "            \n",
    "            # If the hash already exists, the file will be deleted\n",
    "            if hash in hashes:\n",
    "                os.remove(filepath)\n",
    "                print(f'delete: {filepath}')\n",
    "            else:\n",
    "                hashes[hash] = filepath\n",
    "\n",
    "find_duplicates(start_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete grayscale images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple method with color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in os.listdir(start_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(start_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        if len(img.getbands()) == 1:  # if the image is grayscale, it will have only one color channel\n",
    "            print(f\"Deleting grayscale image: {img_path}\")\n",
    "            img.close()  # close the image file before deleting it\n",
    "            os.remove(img_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slow method with RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_greyscale(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    w, h = img.size\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            r, g, b = img.getpixel((i,j))\n",
    "            if r != g != b: \n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(start_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(start_dir, filename)\n",
    "        if is_greyscale(image_path):\n",
    "            print(\"The picture\", filename, \"is black and white.\")\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data distribution insights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=start_dir\n",
    "def get_image_dimensions(folder_path):\n",
    "    image_dimensions = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            with Image.open(filepath) as img:\n",
    "                width, height = img.size\n",
    "                image_dimensions.append((width, height))\n",
    "    return image_dimensions\n",
    "\n",
    "def create_histogram(data, title, xlabel, ylabel, direction): \n",
    "    values = [item[direction] for item in data]  # direction 0= witht and 1= hight\n",
    "    plt.hist(values, bins=100, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    most_common_ratio = statistics.mode(values)\n",
    "    print(f\"The most common aspect ratio is: {most_common_ratio}\")\n",
    "\n",
    "image_dimensions = get_image_dimensions(folder_path)\n",
    "\n",
    "create_histogram(image_dimensions, \"Image Length Histogram\", \"hight\", \"Frequency\",1)\n",
    "create_histogram(image_dimensions, \"Image Width Histogram\", \"Width\", \"Frequency\",0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory path\n",
    "dir_path = start_dir\n",
    "\n",
    "# Empty list for aspect ratios\n",
    "aspect_ratios = []\n",
    "\n",
    "# Go through all the files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Open the picture and get its dimensions\n",
    "        img = Image.open(os.path.join(dir_path, filename))\n",
    "        width, height = img.size\n",
    "\n",
    "        # Calculate the aspect ratio and add it to the list\n",
    "        aspect_ratios.append(width / height)\n",
    "\n",
    "# Create a histogram of the aspect ratios\n",
    "plt.hist(aspect_ratios, bins=50)\n",
    "plt.title('Aspect ratio distribution')\n",
    "plt.xlabel('Aspect ratio')\n",
    "plt.ylabel('number of images')\n",
    "plt.show()\n",
    "\n",
    "# Find and print the most common aspect ratio\n",
    "most_common_ratio = statistics.mode(aspect_ratios)\n",
    "print(f\"The most common aspect ratio is: {most_common_ratio}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data peperation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired output size parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "hoch=600 #height\n",
    "breit=600 #width"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "throwing away small images under defined threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory\n",
    "dir_path = start_dir\n",
    "\n",
    "path_list=[]\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(dir_path, filename)\n",
    "        # Open the picture and get its dimensions\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "            #### Specify threshold again here!!!!!!!! ###\n",
    "            # If the dimensions are smaller than requested, delete the file\n",
    "            if width < breit or height < hoch:\n",
    "                path_list.append(img_path)\n",
    "                print(f\"File {filename} delete\")\n",
    "\n",
    "for path in path_list:\n",
    "    os.remove(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resizing of images to the same size with cutting equaly at the sides and at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=start_dir\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(dir_path, filename)\n",
    "        # Open the picture and get its dimensions\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "            # Determine the size of the square crop\n",
    "            size = min(width, height)\n",
    "\n",
    "            # If the image is wider than it is tall, crop equally from left and right\n",
    "            if width > height:\n",
    "                left = (width - size)/2\n",
    "                right = (width + size)/2\n",
    "                top = 0\n",
    "                bottom = size\n",
    "            # If the image is taller than it is wide, crop from the bottom\n",
    "            else:\n",
    "                left = 0\n",
    "                right = size\n",
    "                top = height\n",
    "                bottom = height - size\n",
    "\n",
    "            img_cropped = img.crop((left, top, right, bottom))\n",
    "            # Save the cropped image, overwriting the original\n",
    "            img_cropped.save(img_path)\n",
    "            print(f\"File {filename} was cropped.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resizing of images to the same size with bicubic downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=start_dir\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(dir_path, filename)\n",
    "        # Open the picture\n",
    "        with Image.open(img_path) as img:\n",
    "            # Resize the image using bicubic interpolation\n",
    "            img_resized = img.resize((hoch,breit), Image.BICUBIC)\n",
    "            # Save the resized image, overwriting the original\n",
    "            img_resized.save(img_path)\n",
    "            print(f\"File {filename} was scaled and overwritten.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting human data into train / test and downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (200, 200)\n",
    "\n",
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = f\"../human_process_results/data/Humans_final_{hoch}\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = f\"../human_process_results/data/Humans_final_{output_size[1]}\"\n",
    "\n",
    "test_low_res_folder = f\"../human_process_results/data/Humans_final_{output_size[1]}_test\"\n",
    "test_original = f\"../human_process_results/data/Humans_final_{hoch}_test\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "if not os.path.exists(test_low_res_folder):\n",
    "    os.makedirs(test_low_res_folder)\n",
    "if not os.path.exists(test_original):\n",
    "    os.makedirs(test_original)\n",
    "\n",
    "number_images = len(os.listdir(folder_path))\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "    # Check if the file is an image (optional)\n",
    "    if number<=0.8*number_images:\n",
    "      # Construct the full path to the image file\n",
    "      image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "      # Apply downsampling to the image\n",
    "      downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "      # Save the downscaled image\n",
    "      output_filename = f\"downsampled_{filename}\"\n",
    "      output_path = os.path.join(output_folder_path, output_filename)\n",
    "      downsampled_image.save(output_path)\n",
    "\n",
    "    else:\n",
    "      # Construct the full path to the image file\n",
    "      image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "      image = Image.open(image_path)\n",
    "      image.save(os.path.join(test_original, filename))\n",
    "\n",
    "\n",
    "      # Apply downsampling to the image\n",
    "      downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "      # Save the downscaled image\n",
    "      output_filename = f\"downsampled_{filename}\"\n",
    "      output_path = os.path.join(test_low_res_folder, output_filename)\n",
    "      downsampled_image.save(output_path)\n",
    "\n",
    "      os.remove(os.path.join(folder_path, filename))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dog dataset processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info: the dog datasets we use is split into train and test data by default (validation split is done via model training later and not saved to disk into seperate folders), same size and all RGB. So preprocessing is just creating the low resolution data for model input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating low resolution input dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = \"C:/Users/a829727/Downloads/archive/Humans_final\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = \"C:/Users/a829727/Downloads/archive/Humans_final_200\"\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "\n",
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (200, 200)\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "  # Construct the full path to the image file\n",
    "  image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "  # Apply downsampling to the image\n",
    "  downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "  # Save the downscaled image\n",
    "  output_filename = f\"downsampled_{filename}\"\n",
    "  output_path = os.path.join(output_folder_path, output_filename)\n",
    "  downsampled_image.save(output_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating low resolution input dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image_path, output_size):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform downsampling using bicubic interpolation\n",
    "    downscaled_image = image.resize(output_size, resample=Image.BICUBIC)\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = \"/kaggle/input/animal-faces/afhq/train/dog\"\n",
    "\n",
    "# Defining folder for downscaled images serving for input for modelling (&upscaling)\n",
    "output_folder_path = \"/kaggle/working/dog_low_res\"\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "\n",
    "# Output size for downsampling (by a factor of 3)\n",
    "output_size = (128, 128)\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for number, filename in enumerate(os.listdir(folder_path)):\n",
    "\n",
    "  # Construct the full path to the image file\n",
    "  image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "  # Apply downsampling to the image\n",
    "  downsampled_image = downsample_image(image_path, output_size)\n",
    "\n",
    "  # Save the downscaled image\n",
    "  output_filename = f\"downsampled_{filename}\"\n",
    "  output_path = os.path.join(output_folder_path, output_filename)\n",
    "  downsampled_image.save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
