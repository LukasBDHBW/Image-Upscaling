{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Cross validation notebook\n","#### (all adapted to dog dataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1687459037407,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"Evh_r8dmRavT"},"outputs":[],"source":["from PIL import Image\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","import os\n","from torch.utils.data import DataLoader, Dataset\n","import math\n","from torchvision.transforms import ColorJitter, Normalize\n","from torch.utils.data import ConcatDataset\n","from torch.utils.data import Subset\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import DataLoader, random_split\n","import numpy as np\n","from tqdm import tqdm\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### creating PyTorch dataset\n","##### note: dataloaders are not defined here, since for cross validation data loaders have to change for every fold"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6766,"status":"ok","timestamp":1687458495733,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"8BjeNxVYHef6"},"outputs":[],"source":["low_res_folder = \"/kaggle/working/dog_low_res\"\n","high_res_folder = \"/kaggle/input/animal-faces/afhq/train/dog\"\n","\n","\n","# === creating dataset with all images ===\n","class CustomDataset(Dataset):\n","    def __init__(self, low_res_folder, high_res_folder, transform=None):\n","        self.low_res_folder = low_res_folder\n","        self.high_res_folder = high_res_folder\n","        self.low_res_images = sorted(os.listdir(low_res_folder))\n","        self.high_res_images = sorted(os.listdir(high_res_folder))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.low_res_images)\n","\n","    def __getitem__(self, index):\n","        low_res_image = Image.open(os.path.join(self.low_res_folder, self.low_res_images[index]))\n","        high_res_image = Image.open(os.path.join(self.high_res_folder, self.high_res_images[index]))\n","\n","        if self.transform is not None:\n","            low_res_image = self.transform(low_res_image)\n","            high_res_image = self.transform(high_res_image)\n","\n","        return low_res_image, high_res_image\n","\n","\n","base_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# dataset\n","dataset = CustomDataset(low_res_folder, high_res_folder, transform=base_transform)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### bicubic"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class bicubic(nn.Module):\n","    def __init__(self):\n","        super(bicubic, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        return x\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eRnCPEdja_mT"},"source":["### SRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gzlOYjOZVy8"},"outputs":[],"source":["# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.interpolation = nn.Upsample(scale_factor=4, mode='bicubic')\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)\n","        self.relu3 = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.interpolation(x)\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.relu3(self.conv3(x))\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIwglB9obBWf"},"source":["### FSRCNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687459044090,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"r41JedVuIaFM"},"outputs":[],"source":["# Load the trained model\n","class FSRCNN(nn.Module):\n","    def __init__(self, d=116, s=15, m=3):\n","        super(FSRCNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, d, kernel_size=5, padding=2)\n","        self.relu1 = nn.PReLU(d)\n","\n","        self.conv2 = nn.Conv2d(d, s, kernel_size=1)\n","        self.relu2 = nn.PReLU(s)\n","\n","        self.mapping = nn.Sequential(*[nn.Sequential(\n","            nn.Conv2d(s, s, kernel_size=3, padding=1),\n","            nn.PReLU(s)\n","        ) for _ in range(m)])\n","\n","        self.conv3 = nn.Conv2d(s, d, kernel_size=1)\n","        self.relu3 = nn.PReLU(d)\n","        \n","        # Deconvolution for upscaling to desired size\n","        self.deconv = nn.ConvTranspose2d(d, 3, kernel_size=9, stride=4, padding=4, output_padding=3)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.mapping(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.deconv(x)\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ESPCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ESPCN(nn.Module):\n","    def __init__(self, upscale_factor=4, num_channels=3):\n","        super(ESPCN, self).__init__()\n","        self.upscale_factor = upscale_factor\n","        \n","        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=5, padding=2)\n","        self.relu1 = nn.ReLU()\n","        \n","        # Subpixel convolution with pixle shuffle for upscaling to desired size\n","        self.conv2 = nn.Conv2d(64, num_channels * upscale_factor ** 2, kernel_size=3, padding=1)\n","        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n","        self.relu2 = nn.ReLU()\n","    \n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.pixel_shuffle(self.conv2(x))\n","        x = self.relu2(x)\n","        return x\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### cross validation of bicubic interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","\n","# Cross-validation setup\n","num_folds = 5\n","fold_len = np.floor(len(indices) / num_folds).astype('int')\n","\n","batch_size = 16\n","total_psnr = 0\n","\n","for fold in range(num_folds):\n","    # Calculate start and end indices for validation data\n","    val_start = fold * fold_len\n","    val_end = (fold + 1) * fold_len\n","\n","\n","    val_indices = indices[val_start:val_end]\n","\n","\n","\n","\n","    val_dataset = Subset(dataset, val_indices)\n","\n","    # Create train and validation data loaders\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    # Training hardware\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # instance of the CNN model\n","    model = bicubic().to(device)\n","\n","    # loss function and optimizer\n","    criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","\n","\n","    # Validating the model (on validation data)\n","    val_loss = 0\n","    number_batches = 0\n","    for input_data, desired_data in val_loader:\n","        number_batches += 1\n","\n","        # Input and desired images to device\n","        input_data = input_data.to(device)\n","        desired_data = desired_data.to(device)\n","\n","        # Forward pass\n","        output_images = model(input_data)\n","\n","        # Calculate loss\n","        loss = criterion(output_images, desired_data)\n","        val_loss += loss.item()\n","\n","    val_loss_avg = val_loss / number_batches\n","\n","    # Print val psnr per fold \n","    psnr = 10 * math.log10(1 / val_loss_avg)\n","    total_psnr += psnr\n","    print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","\n","# print total average psnr over all folds\n","total_psnr = total_psnr/num_folds\n","print(f\"Total PSNR:{total_psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### cross validation for CNN models\n","##### Important: two cells have to be changed if you want to do cross val for antoher model (model & learning rate cell)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374252,"status":"ok","timestamp":1687460343759,"user":{"displayName":"Lukas Gren","userId":"03474024525300725669"},"user_tz":-120},"id":"61XUL-tBbCVo","outputId":"d4577f02-c024-4aa1-aaa6-010bf81ce6fe"},"outputs":[],"source":["dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","\n","# Cross validation setup\n","num_folds = 5\n","fold_len = np.floor(len(indices) / num_folds).astype('int')\n","\n","batch_size = 32\n","total_psnr = 0\n","\n","graph_values_folds = []\n","\n","# looping through all folds\n","for fold in range(num_folds):\n","    \n","    # Training hardware\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # instance of the CNN model\n","    model = ESPCN().to(device) ### CHANGE MODEL HERE ###\n","\n","    graph_values_epochs=[]\n","\n","\n","    # Calculating start and end indices for validation data\n","    val_start = fold * fold_len\n","    val_end = (fold + 1) * fold_len\n","\n","\n","    # Split indices into train and validation\n","    val_indices = indices[val_start:val_end]\n","    train_indices = indices[:val_start] + indices[val_end:]\n","\n","\n","    # Create train and validation datasets\n","    train_dataset = Subset(dataset, train_indices)\n","    val_dataset = Subset(dataset, val_indices)\n","\n","\n","    # Create train and validation data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    \n","    # hyperparameters\n","    learning_rate = 0.002639203815995965 ### CHANGE LEARNING RATE ACCORDING TO MODEL ###\n","    num_epochs = 50\n","    early_stopping_patience = 3\n","    best_val_loss = float('inf')\n","    epochs_without_improvement = 0\n","\n","    # loss function and optimizer\n","    criterion = nn.MSELoss() # note: standard MSE is used, PSNR normally not used for training (just as metric at the end)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training process\n","    psnr_fold = 0\n","    for epoch in range(num_epochs):\n","        for input_data, desired_data in train_loader:\n","            # Move input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","\n","            # backward step / optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Print training loss per epoch\n","        psnr = 10 * math.log10(1 / loss.item())\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, PSNR: {psnr}\")\n","\n","        # Validating the model (on validation data)\n","        val_loss = 0\n","        number_batches = 0\n","        for input_data, desired_data in val_loader:\n","            number_batches += 1\n","\n","            # Input and desired images to device\n","            input_data = input_data.to(device)\n","            desired_data = desired_data.to(device)\n","\n","            # Forward pass\n","            output_images = model(input_data)\n","\n","            # Calculate loss\n","            loss = criterion(output_images, desired_data)\n","            val_loss += loss.item()\n","\n","        val_loss_avg = val_loss / number_batches\n","\n","        # Print val psnr per epoch\n","        psnr = 10 * math.log10(1 / val_loss_avg)\n","        psnr_fold += psnr\n","        print(f\"Loss (validation): {val_loss_avg:.4f}, PSNR (validation): {psnr}\")\n","        graph_values_epochs.append(psnr)\n","\n","        # Check for early stopping\n","        if val_loss_avg < best_val_loss:\n","            best_val_loss = val_loss_avg\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","            if epochs_without_improvement == early_stopping_patience:\n","                print(\"Early stopping triggered. No improvement in validation loss.\")\n","                total_psnr += psnr_fold / (epoch+1)\n","                break\n","\n","    if epoch+1 == 50:\n","        total_psnr += psnr_fold / num_epochs\n","    graph_values_folds.append(graph_values_epochs)\n","\n","# print total average psnr over all folds\n","total_psnr = total_psnr/num_folds\n","print(f\"Total PSNR:{total_psnr}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### plot for PSNR over epochs for different folds\n","#### Note: make sure that the right cell for the model you want to plot cross val results for has been the last one executed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s9yDnLZLDk5"},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.offline as pyo\n","import numpy as np\n","\n","data = graph_values_folds\n","\n","fig = go.Figure()\n","\n","# Calculate the average of all sublists\n","min_length = min(len(sublist) for sublist in data)\n","average_line = np.mean([sublist[:min_length] for sublist in data], axis=0)\n","\n","for sublist in data:\n","    fig.add_trace(go.Scatter(x=list(range(len(sublist))), y=sublist, mode='lines'))\n","\n","fig.add_trace(go.Scatter(x=list(range(min_length)), y=average_line, mode='lines', name='Average'))\n","\n","fig.update_xaxes(title_text='Epoch')\n","fig.update_yaxes(title_text='PSNR')\n","\n","pyo.plot(fig, filename='PSNR_over_epochs_folds.html')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# with open('output.txt', 'w') as file:\n","#     content = ', '.join(map(str, average_line))\n","#     file.write(content)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### plots average lines of all models into one graph (data for that has been hard coded down below for dog dataset)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"mode":"lines","name":"ESPCN","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10],"y":[26.086121550141637,26.500422264288527,26.660102869339347,26.83295133126692,26.874811841738115,26.80295849286863,26.89856834174961,26.577675507482166,26.90733575693053,26.942565204813786,26.177937904679688,27.013983015012787,26.98787022208295]},{"mode":"lines","name":"FSRCNN","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10],"y":[20.97941350563986,23.837119969495017,24.283865205179197,25.01499516918279,25.319767329046147,25.941155081439064,26.28973173908351,26.394773912719252,26.47659645420195,26.580975677159312]},{"mode":"lines","name":"SRCNN","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10],"y":[25.16832292503419,26.51897940633001,26.67516703671364,26.413521274413796,26.897176324337284,26.868541243839964,26.832665437064396,26.710654141118802,27.021316015179128,27.040426034845733,26.11233959631153]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"xaxis":{"title":{"text":"Epoch"}},"yaxis":{"title":{"text":"PSNR"}}}}},"metadata":{},"output_type":"display_data"}],"source":["import plotly.graph_objects as go\n","import plotly.offline as pyo\n","import numpy as np\n","data = [[26.086121550141637, 26.500422264288527, 26.660102869339347, 26.83295133126692, 26.874811841738115, 26.80295849286863, 26.89856834174961, 26.577675507482166, 26.90733575693053, 26.942565204813786, 26.177937904679688, 27.013983015012787, 26.98787022208295],[20.97941350563986, 23.837119969495017, 24.283865205179197, 25.01499516918279, 25.319767329046147, 25.941155081439064, 26.28973173908351, 26.394773912719252, 26.47659645420195, 26.580975677159312],[25.16832292503419, 26.51897940633001, 26.67516703671364, 26.413521274413796, 26.897176324337284, 26.868541243839964, 26.832665437064396, 26.710654141118802, 27.021316015179128, 27.040426034845733, 26.11233959631153]]\n","\n","fig = go.Figure()\n","\n","# Calculate the average of all sublists\n","min_length = min(len(sublist) for sublist in data)\n","\n","\n","fig.add_trace(go.Scatter(x=list(range(len(sublist))), y=data[0], mode='lines', name='ESPCN'))\n","fig.add_trace(go.Scatter(x=list(range(len(sublist))), y=data[1], mode='lines', name='FSRCNN'))\n","fig.add_trace(go.Scatter(x=list(range(len(sublist))), y=data[2], mode='lines', name=\"SRCNN\"))\n","\n","\n","fig.update_xaxes(title_text='Epoch')\n","fig.update_yaxes(title_text='PSNR')\n","\n","#pyo.plot(fig, filename='PSNR_over_epochs_folds.html')\n","fig"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
